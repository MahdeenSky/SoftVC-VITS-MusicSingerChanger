{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdeenSky/SoftVC-VITS-MusicSingerChanger/blob/main/so_vits_svc_4_0_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2P9H2ubS5msc"
      },
      "outputs": [],
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b-4eVF_7T_YF"
      },
      "outputs": [],
      "source": [
        "#@title Setup 1 (just run this once)\n",
        "import os\n",
        "import glob\n",
        "!git clone https://github.com/effusiveperiscope/so-vits-svc -b eff-4.0\n",
        "os.chdir('so-vits-svc')\n",
        "# install requirements one-at-a-time to ignore exceptions\n",
        "!cat requirements.txt | xargs -n 1 pip install --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "!pip install praat-parselmouth\n",
        "!pip install ipywidgets\n",
        "!pip install huggingface_hub\n",
        "!pip install pip==23.0.1 # fix pip version for fairseq install\n",
        "!pip install fairseq==0.12.2\n",
        "!jupyter nbextension enable --py widgetsnbextension\n",
        "existing_files = glob.glob('/content/**/*.*', recursive=True)\n",
        "!pip install numpy==1.21\n",
        "!pip install --upgrade protobuf=3.9.2\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install tensorflow==2.11.0 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K7aE5WZqdStA"
      },
      "outputs": [],
      "source": [
        "#@title Setup 2 (just run this once)\n",
        "os.chdir('/content/so-vits-svc') # force working-directory to so-vits-svc - this line is just for safety and is probably not required\n",
        "\n",
        "import tarfile\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "# taken from https://github.com/CookiePPP/cookietts/blob/master/CookieTTS/utils/dataset/extract_unknown.py\n",
        "def extract(path):\n",
        "    if path.endswith(\".zip\"):\n",
        "        with ZipFile(path, 'r') as zipObj:\n",
        "           zipObj.extractall(os.path.split(path)[0])\n",
        "    elif path.endswith(\".tar.bz2\"):\n",
        "        tar = tarfile.open(path, \"r:bz2\")\n",
        "        tar.extractall(os.path.split(path)[0])\n",
        "        tar.close()\n",
        "    elif path.endswith(\".tar.gz\"):\n",
        "        tar = tarfile.open(path, \"r:gz\")\n",
        "        tar.extractall(os.path.split(path)[0])\n",
        "        tar.close()\n",
        "    elif path.endswith(\".tar\"):\n",
        "        tar = tarfile.open(path, \"r:\")\n",
        "        tar.extractall(os.path.split(path)[0])\n",
        "        tar.close()\n",
        "    elif path.endswith(\".7z\"):\n",
        "        import py7zr\n",
        "        archive = py7zr.SevenZipFile(path, mode='r')\n",
        "        archive.extractall(path=os.path.split(path)[0])\n",
        "        archive.close()\n",
        "    else:\n",
        "        raise NotImplementedError(f\"{path} extension not implemented.\")\n",
        "\n",
        "# taken from https://github.com/CookiePPP/cookietts/tree/master/CookieTTS/_0_download/scripts\n",
        "\n",
        "# megatools download urls\n",
        "win64_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-win64.zip\"\n",
        "win32_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-win32.zip\"\n",
        "linux_url = \"https://megatools.megous.com/builds/builds/megatools-1.11.1.20230212-linux-x86_64.tar.gz\"\n",
        "# download megatools\n",
        "from sys import platform\n",
        "import os\n",
        "import urllib.request\n",
        "import subprocess\n",
        "from time import sleep\n",
        "\n",
        "if platform == \"linux\" or platform == \"linux2\":\n",
        "        dl_url = linux_url\n",
        "elif platform == \"darwin\":\n",
        "    raise NotImplementedError('MacOS not supported.')\n",
        "elif platform == \"win32\":\n",
        "        dl_url = win64_url\n",
        "else:\n",
        "    raise NotImplementedError ('Unknown Operating System.')\n",
        "\n",
        "dlname = dl_url.split(\"/\")[-1]\n",
        "if dlname.endswith(\".zip\"):\n",
        "    binary_folder = dlname[:-4] # remove .zip\n",
        "elif dlname.endswith(\".tar.gz\"):\n",
        "    binary_folder = dlname[:-7] # remove .tar.gz\n",
        "else:\n",
        "    raise NameError('downloaded megatools has unknown archive file extension!')\n",
        "\n",
        "if not os.path.exists(binary_folder):\n",
        "    print('\"megatools\" not found. Downloading...')\n",
        "    if not os.path.exists(dlname):\n",
        "        urllib.request.urlretrieve(dl_url, dlname)\n",
        "    assert os.path.exists(dlname), 'failed to download.'\n",
        "    extract(dlname)\n",
        "    sleep(0.10)\n",
        "    os.unlink(dlname)\n",
        "    print(\"Done!\")\n",
        "\n",
        "\n",
        "binary_folder = os.path.abspath(binary_folder)\n",
        "\n",
        "def megadown(download_link, filename='.', verbose=False):\n",
        "    \"\"\"Use megatools binary executable to download files and folders from MEGA.nz .\"\"\"\n",
        "    filename = ' --path \"'+os.path.abspath(filename)+'\"' if filename else \"\"\n",
        "    wd_old = os.getcwd()\n",
        "    os.chdir(binary_folder)\n",
        "    try:\n",
        "        if platform == \"linux\" or platform == \"linux2\":\n",
        "            subprocess.call(f'./megatools dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}', shell=True)\n",
        "        elif platform == \"win32\":\n",
        "            subprocess.call(f'megatools.exe dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}', shell=True)\n",
        "    except:\n",
        "        os.chdir(wd_old) # don't let user stop download without going back to correct directory first\n",
        "        raise\n",
        "    os.chdir(wd_old)\n",
        "    return filename\n",
        "\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "import gdown\n",
        "from os.path import exists\n",
        "\n",
        "def request_url_with_progress_bar(url, filename):\n",
        "    class DownloadProgressBar(tqdm):\n",
        "        def update_to(self, b=1, bsize=1, tsize=None):\n",
        "            if tsize is not None:\n",
        "                self.total = tsize\n",
        "            self.update(b * bsize - self.n)\n",
        "    \n",
        "    def download_url(url, filename):\n",
        "        with DownloadProgressBar(unit='B', unit_scale=True,\n",
        "                                 miniters=1, desc=url.split('/')[-1]) as t:\n",
        "            filename, headers = urllib.request.urlretrieve(url, filename=filename, reporthook=t.update_to)\n",
        "            print(\"Downloaded to \"+filename)\n",
        "    download_url(url, filename)\n",
        "\n",
        "\n",
        "def download(urls, dataset='', filenames=None, force_dl=False, username='', password='', auth_needed=False):\n",
        "    assert filenames is None or len(urls) == len(filenames), f\"number of urls does not match filenames. Expected {len(filenames)} urls, containing the files listed below.\\n{filenames}\"\n",
        "    assert not auth_needed or (len(username) and len(password)), f\"username and password needed for {dataset} Dataset\"\n",
        "    if filenames is None:\n",
        "        filenames = [None,]*len(urls)\n",
        "    for i, (url, filename) in enumerate(zip(urls, filenames)):\n",
        "        print(f\"Downloading File from {url}\")\n",
        "        #if filename is None:\n",
        "        #    filename = url.split(\"/\")[-1]\n",
        "        if filename and (not force_dl) and exists(filename):\n",
        "            print(f\"{filename} Already Exists, Skipping.\")\n",
        "            continue\n",
        "        if 'drive.google.com' in url:\n",
        "            assert 'https://drive.google.com/uc?id=' in url, 'Google Drive links should follow the format \"https://drive.google.com/uc?id=1eQAnaoDBGQZldPVk-nzgYzRbcPSmnpv6\".\\nWhere id=XXXXXXXXXXXXXXXXX is the Google Drive Share ID.'\n",
        "            gdown.download(url, filename, quiet=False)\n",
        "        elif 'mega.nz' in url:\n",
        "            megadown(url, filename)\n",
        "        else:\n",
        "            #urllib.request.urlretrieve(url, filename=filename) # no progress bar\n",
        "            request_url_with_progress_bar(url, filename) # with progress bar\n",
        "\n",
        "import huggingface_hub\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "class HFModels:\n",
        "    def __init__(self, repo = \"therealvul/so-vits-svc-4.0\", \n",
        "            model_dir = \"hf_vul_models\"):\n",
        "        self.model_repo = huggingface_hub.Repository(local_dir=model_dir,\n",
        "            clone_from=repo, skip_lfs_files=True)\n",
        "        self.repo = repo\n",
        "        self.model_dir = model_dir\n",
        "\n",
        "        self.model_folders = os.listdir(model_dir)\n",
        "        self.model_folders.remove('.git')\n",
        "        self.model_folders.remove('.gitattributes')\n",
        "\n",
        "    def list_models(self):\n",
        "        return self.model_folders\n",
        "\n",
        "    # Downloads model;\n",
        "    # copies config to target_dir and moves model to target_dir\n",
        "    def download_model(self, model_name, target_dir):\n",
        "        if not model_name in self.model_folders:\n",
        "            raise Exception(model_name + \" not found\")\n",
        "        model_dir = self.model_dir\n",
        "        charpath = os.path.join(model_dir,model_name)\n",
        "\n",
        "        gen_pt = next(x for x in os.listdir(charpath) if x.startswith(\"G_\"))\n",
        "        cfg = next(x for x in os.listdir(charpath) if x.endswith(\"json\"))\n",
        "        try:\n",
        "          clust = next(x for x in os.listdir(charpath) if x.endswith(\"pt\"))\n",
        "        except StopIteration as e:\n",
        "          print(\"Note - no cluster model for \"+model_name)\n",
        "          clust = None\n",
        "\n",
        "        if not os.path.exists(target_dir):\n",
        "            os.makedirs(target_dir, exist_ok=True)\n",
        "\n",
        "        gen_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
        "            filename = model_name + \"/\" + gen_pt) # this is a symlink\n",
        "        \n",
        "        if clust is not None:\n",
        "          clust_dir = huggingface_hub.hf_hub_download(repo_id = self.repo,\n",
        "              filename = model_name + \"/\" + clust) # this is a symlink\n",
        "          shutil.move(os.path.realpath(clust_dir), os.path.join(target_dir, clust))\n",
        "          clust_out = os.path.join(target_dir, clust)\n",
        "        else:\n",
        "          clust_out = None\n",
        "\n",
        "        shutil.copy(os.path.join(charpath,cfg),os.path.join(target_dir, cfg))\n",
        "        shutil.move(os.path.realpath(gen_dir), os.path.join(target_dir, gen_pt))\n",
        "\n",
        "        return {\"config_path\": os.path.join(target_dir,cfg),\n",
        "            \"generator_path\": os.path.join(target_dir,gen_pt),\n",
        "            \"cluster_path\": clust_out}\n",
        "\n",
        "# Example usage\n",
        "# vul_models = HFModels()\n",
        "# print(vul_models.list_models())\n",
        "# print(\"Applejack (singing)\" in vul_models.list_models())\n",
        "# vul_models.download_model(\"Applejack (singing)\",\"models/Applejack (singing)\")\n",
        "\n",
        "    print(\"Finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JntsKHUGr9kD"
      },
      "outputs": [],
      "source": [
        "#@title Download ContentVec (just run this once)\n",
        "os.chdir('/content/so-vits-svc') # force working-directory to so-vits-svc - this line is just for safety and is probably not required\n",
        "download([\"https://huggingface.co/therealvul/so-vits-svc-4.0-init/resolve/main/checkpoint_best_legacy_500.pt\"], filenames=[\"hubert/checkpoint_best_legacy_500.pt\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "oFr2MWaQfR6X",
        "outputId": "97a2fde2-0375-4ecc-c193-53d9e6bdeec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading File from https://mega.nz/file/nYpAiTpK#2o8SxEOw6SyTnOMFRYrzlvC9skafcx8Mc40SsSBYZxg\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-e2dd21cd9ea5>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m            filenames=[os.path.join(os.getcwd(),model_url.split(\"/\")[-1])])\n\u001b[1;32m     19\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_url\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-3-d71ce853370a>\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(urls, dataset, filenames, force_dl, username, password, auth_needed)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'mega.nz'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mmegadown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m#urllib.request.urlretrieve(url, filename=filename) # no progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d71ce853370a>\u001b[0m in \u001b[0;36mmegadown\u001b[0;34m(download_link, filename, verbose)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linux\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"linux2\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./megatools dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mplatform\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"win32\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'megatools.exe dl{filename}{\" --debug http\" if verbose else \"\"} {download_link}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Including KeyboardInterrupt, wait handled that.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1915\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@title Custom Model Download\n",
        "#@markdown Supported URL types: \n",
        "#@markdown * Google Drive zip\n",
        "#@markdown * MEGA zip\n",
        "#@markdown * Direct zip (+HuggingFace /resolve/ link)\n",
        "\n",
        "#@markdown List of models: \n",
        "#@markdown * https://docs.google.com/spreadsheets/d/e/2PACX-1vTaZuH6URWNDZafDS5bQScdWPQcCrr37vCzw8R17Ikr2avXMZELv4vbLVEO9wuTjdqezrQJQCnM0KPf/pubhtml\n",
        "\n",
        "#@markdown Example URLs:\n",
        "#@markdown * Kanye west model: https://mega.nz/file/P7hWwCoQ#s0OICnRbTpcUjUIS7iQPIlYwBVelZXzm_-1LLPSUd2Y\n",
        "\n",
        "\n",
        "import re\n",
        "model_url = \"https://mega.nz/file/nYpAiTpK#2o8SxEOw6SyTnOMFRYrzlvC9skafcx8Mc40SsSBYZxg\" #@param {\"type\": \"string\"}\n",
        "if \"huggingface.co\" in model_url.lower():\n",
        "  download([re.sub(r\"/blob/\",\"/resolve/\",model_url)], \n",
        "           filenames=[os.path.join(os.getcwd(),model_url.split(\"/\")[-1])])\n",
        "else:\n",
        "  download([model_url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FHg8Gx8ihDk",
        "outputId": "df2a8c90-f475-40fb-f9f1-af6ae2840380"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "extracting zip /content/so-vits-svc/megatools-1.11.1.20230212-linux-x86_64/Mori_Calliope.zip\n"
          ]
        }
      ],
      "source": [
        "#@title Extract .zip Downloads - Step o.2\n",
        "# download speaker model files into 'models' directory\n",
        "#import glob, os, shutil\n",
        "#from pathlib import Path\n",
        "#os.makedirs('models', exist_ok=True)\n",
        "#model_zip_paths = glob.glob('/content/**/*.zip', recursive=True)\n",
        "#for model_zip_path in model_zip_paths:\n",
        "#    extract(model_zip_path) # extract inplace\n",
        "#    ckpts_inplace = glob.glob('./*.pth')\n",
        "#    json_inplace = glob.glob('./*.json')\n",
        "#    if os.path.exists(os.path.splitext(model_zip_path)[0]):\n",
        "#      shutil.move(os.path.splitext(model_zip_path)[0],'models')\n",
        "#    elif len(ckpts_inplace):\n",
        "#      for f in ckpts_inplace:\n",
        "#        os.makedirs('models/'+Path(model_zip_path).stem, \n",
        "#                      exist_ok=True)\n",
        "#        shutil.move(f,'models/'+Path(model_zip_path).stem)\n",
        "#      for f in json_inplace:\n",
        "#        shutil.move(f,'models/'+Path(model_zip_path).stem)\n",
        "        #@title Extract .zip Downloads - Step o.2\n",
        "# download speaker model files into 'models' directory\n",
        "import glob, os, shutil\n",
        "from pathlib import Path\n",
        "os.makedirs('models', exist_ok=True)\n",
        "model_zip_paths = glob.glob('/content/**/*.zip', recursive=True)\n",
        "\n",
        "for model_zip_path in model_zip_paths:\n",
        "    print(\"extracting zip\",model_zip_path)\n",
        "    output_dir = os.path.join('/content/so-vits-svc/models',os.path.basename(os.path.splitext(model_zip_path)[0]).replace(\" \",\"_\"))\n",
        "    \n",
        "    # clean and create output dir\n",
        "    if os.path.exists(output_dir):\n",
        "      shutil.rmtree(output_dir)\n",
        "    os.mkdir(output_dir)\n",
        "    input_base = os.path.dirname(model_zip_path)\n",
        "\n",
        "    # clean input dir (if user stopped an earlier extract and we have dirty files)\n",
        "    ckpts_pre = glob.glob(os.path.join(input_base,'**/*.pth'),recursive=True)\n",
        "    jsons_pre = glob.glob(os.path.join(input_base,'**/config.json'),recursive=True)\n",
        "    for cpkt in ckpts_pre:\n",
        "      os.remove(cpkt)\n",
        "    for json in jsons_pre:\n",
        "      os.remove(json)\n",
        "\n",
        "    # do the extract\n",
        "    extract(model_zip_path)\n",
        "    ckpts = glob.glob(os.path.join(input_base,'**/*.pth'),recursive=True)\n",
        "    jsons = glob.glob(os.path.join(input_base,'**/config.json'),recursive=True)\n",
        "    for ckpt in ckpts:\n",
        "      shutil.move(ckpt,os.path.join(output_dir,os.path.basename(ckpt)))\n",
        "    for json in jsons:\n",
        "      shutil.move(json,os.path.join(output_dir,os.path.basename(json)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK4LI5d1sHIV",
        "outputId": "ed3c830d-b102-40fd-9779-fec8bc802b2a",
        "cellView": "form"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive (To import music files, since uploading/downloading through collab is slow)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "72ba55a171734224b40eee1d35fdab76",
            "17a39cb1f8ed47408c80dcb2682d9be7",
            "e9319a958d7e4865ad08e222acd48f1e",
            "3320a46107784e1eb773e55459db9fff",
            "3d92f9310fb0483a87da14d01d2f7924",
            "4e41361aae754528ac66e1fe3760dcb9",
            "f302a8a5405a476f86ce59d73ea29ccb"
          ]
        },
        "id": "Bpg6Ql1QHEV6",
        "outputId": "3884a18c-61b8-43e6-8f3f-ab17e5c32d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: No clustering model found for Mori_Calliope\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72ba55a171734224b40eee1d35fdab76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Dropdown(options=('Cali',), value='Cali')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17a39cb1f8ed47408c80dcb2682d9be7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "IntText(value=0, description='Transpose')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9319a958d7e4865ad08e222acd48f1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatText(value=0.0, description='Clustering Ratio')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3320a46107784e1eb773e55459db9fff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FloatText(value=0.4, description='Noise Scale')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d92f9310fb0483a87da14d01d2f7924",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Checkbox(value=False, description='Auto pitch f0 (do not use for singing)')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e41361aae754528ac66e1fe3760dcb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Convert', style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f302a8a5405a476f86ce59d73ea29ccb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Delete all audio files', style=ButtonStyle())"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Open the file explorer on the left of your screen and drag-and-drop an audio file anywhere. Then run the below cell, and press convert.\n",
        "import os\n",
        "import glob\n",
        "import json\n",
        "import copy\n",
        "import logging\n",
        "import io\n",
        "from ipywidgets import widgets\n",
        "from pathlib import Path\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "os.chdir('/content/so-vits-svc')\n",
        "\n",
        "import torch\n",
        "from inference import infer_tool\n",
        "from inference import slicer\n",
        "from inference.infer_tool import Svc\n",
        "import soundfile\n",
        "import numpy as np\n",
        "\n",
        "MODELS_DIR = \"models\"\n",
        "\n",
        "def get_speakers():\n",
        "  speakers = []\n",
        "  for _,dirs,_ in os.walk(MODELS_DIR):\n",
        "    for folder in dirs:\n",
        "      cur_speaker = {}\n",
        "      # Look for G_****.pth\n",
        "      g = glob.glob(os.path.join(MODELS_DIR,folder,'G_*.pth'))\n",
        "      if not len(g):\n",
        "        print(\"Skipping \"+folder+\", no G_*.pth\")\n",
        "        continue\n",
        "      cur_speaker[\"model_path\"] = g[0]\n",
        "      cur_speaker[\"model_folder\"] = folder\n",
        "\n",
        "      # Look for *.pt (clustering model)\n",
        "      clst = glob.glob(os.path.join(MODELS_DIR,folder,'*.pt'))\n",
        "      if not len(clst):\n",
        "        print(\"Note: No clustering model found for \"+folder)\n",
        "        cur_speaker[\"cluster_path\"] = \"\"\n",
        "      else:\n",
        "        cur_speaker[\"cluster_path\"] = clst[0]\n",
        "\n",
        "      # Look for config.json\n",
        "      cfg = glob.glob(os.path.join(MODELS_DIR,folder,'*.json'))\n",
        "      if not len(cfg):\n",
        "        print(\"Skipping \"+folder+\", no config json\")\n",
        "        continue\n",
        "      cur_speaker[\"cfg_path\"] = cfg[0]\n",
        "      with open(cur_speaker[\"cfg_path\"]) as f:\n",
        "        try:\n",
        "          cfg_json = json.loads(f.read())\n",
        "        except Exception as e:\n",
        "          print(\"Malformed config json in \"+folder)\n",
        "        for name, i in cfg_json[\"spk\"].items():\n",
        "          cur_speaker[\"name\"] = name\n",
        "          cur_speaker[\"id\"] = i\n",
        "          if not name.startswith('.'):\n",
        "            speakers.append(copy.copy(cur_speaker))\n",
        "\n",
        "    return sorted(speakers, key=lambda x:x[\"name\"].lower())\n",
        "\n",
        "logging.getLogger('numba').setLevel(logging.WARNING)\n",
        "chunks_dict = infer_tool.read_temp(\"inference/chunks_temp.json\")\n",
        "existing_files = []\n",
        "slice_db = -40\n",
        "wav_format = 'wav'\n",
        "\n",
        "class InferenceGui():\n",
        "  def __init__(self):\n",
        "    self.speakers = get_speakers()\n",
        "    self.speaker_list = [x[\"name\"] for x in self.speakers]\n",
        "    self.speaker_box = widgets.Dropdown(\n",
        "        options = self.speaker_list\n",
        "    )\n",
        "    display(self.speaker_box)\n",
        "\n",
        "    def convert_cb(btn):\n",
        "      self.convert()\n",
        "    def clean_cb(btn):\n",
        "      self.clean()\n",
        "\n",
        "    self.convert_btn = widgets.Button(description=\"Convert\")\n",
        "    self.convert_btn.on_click(convert_cb)\n",
        "    self.clean_btn = widgets.Button(description=\"Delete all audio files\")\n",
        "    self.clean_btn.on_click(clean_cb)\n",
        "\n",
        "    self.trans_tx = widgets.IntText(value=0, description='Transpose')\n",
        "    self.cluster_ratio_tx = widgets.FloatText(value=0.0, \n",
        "      description='Clustering Ratio')\n",
        "    self.noise_scale_tx = widgets.FloatText(value=0.4, \n",
        "      description='Noise Scale')\n",
        "    self.auto_pitch_ck = widgets.Checkbox(value=False, description=\n",
        "      'Auto pitch f0 (do not use for singing)')\n",
        "\n",
        "    display(self.trans_tx)\n",
        "    display(self.cluster_ratio_tx)\n",
        "    display(self.noise_scale_tx)\n",
        "    display(self.auto_pitch_ck)\n",
        "    display(self.convert_btn)\n",
        "    display(self.clean_btn)\n",
        "\n",
        "  def convert(self):\n",
        "    trans = int(self.trans_tx.value)\n",
        "    speaker = next(x for x in self.speakers if x[\"name\"] == \n",
        "          self.speaker_box.value)\n",
        "    spkpth2 = os.path.join(os.getcwd(),speaker[\"model_path\"])\n",
        "    print(spkpth2)\n",
        "    print(os.path.exists(spkpth2))\n",
        "\n",
        "    svc_model = Svc(speaker[\"model_path\"], speaker[\"cfg_path\"], \n",
        "      cluster_model_path=speaker[\"cluster_path\"])\n",
        "    \n",
        "    input_filepaths = [f for f in glob.glob('/content/**/*.*', recursive=True)\n",
        "     if f not in existing_files and \n",
        "     any(f.endswith(ex) for ex in ['.wav','.flac','.mp3','.ogg','.opus'])]\n",
        "    for name in input_filepaths:\n",
        "      print(\"Converting \"+os.path.split(name)[-1])\n",
        "      infer_tool.format_wav(name)\n",
        "\n",
        "      wav_path = str(Path(name).with_suffix('.wav'))\n",
        "      wav_name = Path(name).stem\n",
        "      chunks = slicer.cut(wav_path, db_thresh=slice_db)\n",
        "      audio_data, audio_sr = slicer.chunks2audio(wav_path, chunks)\n",
        "\n",
        "      audio = []\n",
        "      for (slice_tag, data) in audio_data:\n",
        "          print(f'#=====segment start, '\n",
        "              f'{round(len(data)/audio_sr, 3)}s======')\n",
        "          \n",
        "          length = int(np.ceil(len(data) / audio_sr *\n",
        "              svc_model.target_sample))\n",
        "          \n",
        "          if slice_tag:\n",
        "              print('jump empty segment')\n",
        "              _audio = np.zeros(length)\n",
        "          else:\n",
        "              # Padding \"fix\" for noise\n",
        "              pad_len = int(audio_sr * 0.5)\n",
        "              data = np.concatenate([np.zeros([pad_len]),\n",
        "                  data, np.zeros([pad_len])])\n",
        "              raw_path = io.BytesIO()\n",
        "              soundfile.write(raw_path, data, audio_sr, format=\"wav\")\n",
        "              raw_path.seek(0)\n",
        "              _cluster_ratio = 0.0\n",
        "              if speaker[\"cluster_path\"] != \"\":\n",
        "                _cluster_ratio = float(self.cluster_ratio_tx.value)\n",
        "              out_audio, out_sr = svc_model.infer(\n",
        "                  speaker[\"name\"], trans, raw_path,\n",
        "                  cluster_infer_ratio = _cluster_ratio,\n",
        "                  auto_predict_f0 = bool(self.auto_pitch_ck.value),\n",
        "                  noice_scale = float(self.noise_scale_tx.value))\n",
        "              _audio = out_audio.cpu().numpy()\n",
        "              pad_len = int(svc_model.target_sample * 0.5)\n",
        "              _audio = _audio[pad_len:-pad_len]\n",
        "          audio.extend(list(infer_tool.pad_array(_audio, length)))\n",
        "          \n",
        "      res_path = os.path.join('/content/',\n",
        "          f'{wav_name}_{trans}_key_'\n",
        "          f'{speaker[\"name\"]}.{wav_format}')\n",
        "      soundfile.write(res_path, audio, svc_model.target_sample,\n",
        "          format=wav_format)\n",
        "      display(Audio(res_path, autoplay=True)) # display audio file\n",
        "    pass\n",
        "\n",
        "  def clean(self):\n",
        "     input_filepaths = [f for f in glob.glob('/content/**/*.*', recursive=True)\n",
        "     if f not in existing_files and \n",
        "     any(f.endswith(ex) for ex in ['.wav','.flac','.mp3','.ogg','.opus'])]\n",
        "     for f in input_filepaths:\n",
        "       os.remove(f)\n",
        "\n",
        "inference_gui = InferenceGui()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}